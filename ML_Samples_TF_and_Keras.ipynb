{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Samples_TF and Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyyTJyVKUsoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp-SNR3cld9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Using TensorFlow and Keras to train a Machine in Deep Learning way'''\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "#batching and shuffling the dataset\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "#Building a deep learning model\n",
        "class AsoModel(Model):\n",
        "  def __init__(self):\n",
        "    super(AsoModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = AsoModel()\n",
        "\n",
        "#Selecting a loss finction \n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "#Selecting an optimizer function\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "#Selecting metrics to measure the loss and the accuracy\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "#Training the built network\n",
        "###@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different behavior during training versus inference\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "#Testing the model\n",
        "###@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different behavior during training versus inference\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)\n",
        "\n",
        "#Using functions about different images\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = 'Epoch: {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "  print(template.format(epoch+1,\n",
        "                        train_loss.result(),\n",
        "                        train_accuracy.result()*100,\n",
        "                        test_loss.result(),\n",
        "                        test_accuracy.result()*100)) \n",
        "\n",
        "#The image classifier is now trained about 98.5% accuracy on this dataset(MNIST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuptlBbPQW1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''TensorFlow sample _ training a Machine with TensorFlow'''\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "#Using Sequential models to make a Network \n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "#returns a vector of \"logits\" or \"log-odds\" scores\n",
        "predictions = model(x_train[:1]).numpy()\n",
        "predictions\n",
        "\n",
        "#Convert logits to \"probabilities\" \n",
        "tf.nn.softmax(predictions).numpy()\n",
        "\n",
        "#returns a scalar 'loss' and an 'accuracy' for each example(in each \"epoch\")\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Training step: train with epoch=5 in 60000 samples\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "#Test step with 1000 samples \n",
        "model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "#Result description: The image classifier is now trained about 98% accuracy on this(MNIST) dataset."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}